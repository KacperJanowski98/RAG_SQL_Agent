{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ollama import Client\n",
    "from pydantic import create_model\n",
    "import inspect, json\n",
    "from inspect import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define the function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(num1:int, num2:int)->int:\n",
    "    \"Compute abc between two numbers\"\n",
    "    return 2*(num1) - 2*(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonschema(f):\n",
    "    \"\"\"\n",
    "    Generate a JSON schema for the input parameters of the given function.\n",
    "\n",
    "    Parameters:\n",
    "        f (FunctionType): The function for which to generate the JSON schema.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the function name, description, and parameters schema.\n",
    "    \"\"\"\n",
    "    kw = {n: (o.annotation, ... if o.default == Parameter.empty else o.default)\n",
    "            for n, o in inspect.signature(f).parameters.items()}\n",
    "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
    "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'abc',\n",
       " 'description': 'Compute abc between two numbers',\n",
       " 'parameters': {'properties': {'num1': {'title': 'Num1', 'type': 'integer'},\n",
       "   'num2': {'title': 'Num2', 'type': 'integer'}},\n",
       "  'required': ['num1', 'num2'],\n",
       "  'title': 'Input for `abc`',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_json = jsonschema(abc)\n",
    "abc_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-groq-tool-use:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ask GPT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "response = client.chat(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"compute abs between 2 and 3\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The absolute value (abs) between 2 and 3 is 1.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'abc',\n",
       "  'args': {'num1': 2, 'num2': 3},\n",
       "  'id': 'c2d3b099-2214-4509-9864-aa1e0ae645e6',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    ").bind_tools([abc_json])\n",
    "\n",
    "result = llm.invoke(\n",
    "    \"compute abs between 2 and 3\"\n",
    ")\n",
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={'model': 'llama3-groq-tool-use:latest', 'created_at': '2024-12-23T19:11:57.374347981Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11297903638, 'load_duration': 805162753, 'prompt_eval_count': 162, 'prompt_eval_duration': 7407000000, 'eval_count': 33, 'eval_duration': 3083000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-dc28d9ac-8ce3-45b1-bdfc-256353ca2101-0' tool_calls=[{'name': 'abc', 'args': {'num1': 2, 'num2': 3}, 'id': 'c2d3b099-2214-4509-9864-aa1e0ae645e6', 'type': 'tool_call'}] usage_metadata={'input_tokens': 162, 'output_tokens': 33, 'total_tokens': 195}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def abc(num1:int, num2:int)->int:\n",
    "    \"Compute abc between two numbers\"\n",
    "    return 2*(num1) - 2*(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Compute abc between two numbers'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3-groq-tool-use:latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [abc]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke(\"Compute abc between 2 and 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'abc',\n",
       "  'args': {'num1': 2, 'num2': 3},\n",
       "  'id': 'cedbf9e6-24f1-4140-ba7a-e01fd877b18c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
