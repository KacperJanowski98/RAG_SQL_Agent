{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_ollama import ChatOllama\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating models so they can be changed as needed\n",
    "sql_agent_llm = ChatOllama(model=\"qwen2.5:14b\", temperature=0)\n",
    "table_extractor_llm = ChatOllama(model=\"qwen2.5:14b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'AntÃ´nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqldb_directory = here(\"data/Chinook.db\")\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqldb_directory}\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Table class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"\n",
    "    Represent a table in the SQL database.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): The name of the table in the SQL database.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Field is an `optional` -- this allows the model to decline to extract it!\n",
    "    \"\"\"\n",
    "    name: Optional[str] = Field(description=\"Name of table in SQL database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Album\\n'\n",
      " 'Artist\\n'\n",
      " 'Customer\\n'\n",
      " 'Employee\\n'\n",
      " 'Genre\\n'\n",
      " 'Invoice\\n'\n",
      " 'InvoiceLine\\n'\n",
      " 'MediaType\\n'\n",
      " 'Playlist\\n'\n",
      " 'PlaylistTrack\\n'\n",
      " 'Track')\n"
     ]
    }
   ],
   "source": [
    "table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "pprint(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(name='Track')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_names}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "structured_llm = table_extractor_llm.with_structured_output(schema=Table)\n",
    "input = \"What are all the genres of Alanis Morisette songs\"\n",
    "structured_llm.invoke(prompt_template.invoke({\"input\": input}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(name='Track')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system = f\"\"\"You will recieve a question.\n",
    "\n",
    "If the question is about **Music**, return **ALL** these tables:\n",
    "  - \"Album\"\n",
    "  - \"Artist\"\n",
    "  - \"Genre\"\n",
    "  - \"MediaType\"\n",
    "  - \"Playlist\"\n",
    "  - \"PlaylistTrack\"\n",
    "  - \"Track\"\n",
    "\n",
    "If the question is about **Business**, return **ALL** these tables:\n",
    "  - \"Customer\"\n",
    "  - \"Employee\"\n",
    "  - \"Invoice\"\n",
    "  - \"InvoiceLine\"\n",
    "\n",
    "If you are unsure, return the full list of all available tables for both Music and Business categories.\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "structured_llm = table_extractor_llm.with_structured_output(schema=Table)\n",
    "input = \"What are all the genres of Alanis Morisette songs\"\n",
    "structured_llm.invoke(prompt_template.invoke({\"question\": input}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'SELECT DISTINCT Name FROM Artist LIMIT 5;'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from typing_extensions import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "def write_query(state: State):\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    structured_llm = table_extractor_llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return result\n",
    "\n",
    "table_chain = prompt_template | table_extractor_llm.with_structured_output(Table)\n",
    "\n",
    "# Create full chain\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        table_names_to_use=lambda x: table_chain.invoke({\"question\": x[\"question\"]})\n",
    "    ) \n",
    "    | write_query\n",
    ")\n",
    "\n",
    "# Test the chain\n",
    "question = \"Give me the names of 5 artists from the database\"\n",
    "query = full_chain.invoke({\"question\": question})\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('AC/DC',), ('Accept',), ('Aerosmith',), ('Alanis Morissette',), ('Alice In Chains',)]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "db.run(query['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "class ChinookSQLAgent:\n",
    "    \"\"\"\n",
    "    A specialized SQL agent that interacts with the Chinook SQL database using an LLM (Large Language Model).\n",
    "\n",
    "    The agent handles SQL queries by mapping user questions to relevant SQL tables based on categories like \"Music\"\n",
    "    and \"Business\". It uses an extraction chain to determine relevant tables based on the question and then\n",
    "    executes queries against the database using the appropriate tables.\n",
    "\n",
    "    Attributes:\n",
    "        sql_agent_llm (ChatOpenAI): The language model used for interpreting and interacting with the database.\n",
    "        db (SQLDatabase): The SQL database object, representing the Chinook database.\n",
    "        full_chain (Runnable): A chain of operations that maps user questions to SQL tables and executes queries.\n",
    "\n",
    "    Methods:\n",
    "        __init__: Initializes the agent by setting up the LLM, connecting to the SQL database, and creating query chains.\n",
    "\n",
    "    Args:\n",
    "        sqldb_directory (str): The directory where the Chinook SQLite database file is located.\n",
    "        llm (str): The name of the LLM model to use (e.g., \"gpt-3.5-turbo\").\n",
    "        llm_temperature (float): The temperature setting for the LLM, controlling the randomness of responses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sqldb_directory: str, llm: str, llm_temerature: float) -> None:\n",
    "        \"\"\"Initializes the ChinookSQLAgent with the LLM and database connection.\n",
    "\n",
    "        Args:\n",
    "            sqldb_directory (str): The directory path to the SQLite database file.\n",
    "            llm (str): The LLM model identifier (e.g., \"gpt-3.5-turbo\").\n",
    "            llm_temerature (float): The temperature value for the LLM, determining the randomness of the model's output.\n",
    "        \"\"\"\n",
    "        self.sql_agent_llm = ChatOllama(\n",
    "            model=llm, temperature=llm_temerature)\n",
    "\n",
    "        self.db = SQLDatabase.from_uri(f\"sqlite:///{sqldb_directory}\")\n",
    "        print(self.db.get_usable_table_names())\n",
    "        category_chain_system = \"\"\"Return the names of the SQL tables that are relevant to the user question. \\\n",
    "        The tables are:\n",
    "\n",
    "        Music\n",
    "        Business\"\"\"     \n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", category_chain_system),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "\n",
    "        table_chain = prompt_template | table_extractor_llm.with_structured_output(Table)\n",
    "\n",
    "        # Create full chain\n",
    "        self.full_chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                table_names_to_use=lambda x: table_chain.invoke({\"question\": x[\"question\"]})\n",
    "            ) \n",
    "            | self.__write_query\n",
    "        )\n",
    "\n",
    "    class State(TypedDict):\n",
    "        question: str\n",
    "        query: str\n",
    "        result: str\n",
    "        answer: str\n",
    "\n",
    "\n",
    "    class QueryOutput(TypedDict):\n",
    "        \"\"\"Generated SQL query.\"\"\"\n",
    "        query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "    def __write_query(self, state: State):\n",
    "        query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "        prompt = query_prompt_template.invoke({\n",
    "            \"dialect\": self.db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": self.db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        })\n",
    "        structured_llm = self.sql_agent_llm.with_structured_output(QueryOutput)\n",
    "        result = structured_llm.invoke(prompt)\n",
    "        return result['query']\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_chinook_sqldb(query: str) -> str:\n",
    "    \"\"\"Query the Chinook SQL Database. Input should be a search query.\"\"\"\n",
    "    # Create an instance of ChinookSQLAgent\n",
    "    agent = ChinookSQLAgent(\n",
    "        sqldb_directory=here(\"data/Chinook.db\"),\n",
    "        llm=\"qwen2.5:14b\",\n",
    "        llm_temerature=0.5\n",
    "    )\n",
    "\n",
    "    query = agent.full_chain.invoke({\"question\": query})\n",
    "\n",
    "    return agent.db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "[(38,), (39,), (40,), (41,), (42,), (43,), (44,), (45,), (46,), (47,), (48,), (49,), (50,)]\n"
     ]
    }
   ],
   "source": [
    "result = query_chinook_sqldb(\"What are all the genres of Alanis Morisette songs\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
